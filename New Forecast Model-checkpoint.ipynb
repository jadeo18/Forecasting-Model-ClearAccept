{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3b0a1748-05ab-4e0f-a887-538f535ddba3",
   "metadata": {},
   "outputs": [],
   "source": [
    "july_df = pd.read_excel(\"July Forecast cleaned.xlsx\")\n",
    "volume_df = pd.read_excel(\"Deals volume cleaned.xlsx\")\n",
    "deals_df = pd.read_excel(\"Number of deals cleaned.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d7199a51-ab78-47eb-a1eb-030cbf6246bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current July pipeline: 320 deals, total volume £269,367,758.65\n"
     ]
    }
   ],
   "source": [
    "# Data cleaning to process the July pipeline data\n",
    "# Filtering out the excluded rows\n",
    "july_df = july_df[july_df['Include / Exclude'] != 'Exclude']\n",
    "\n",
    "# Changing the number of deals to only the count of the titles\n",
    "july_actual_deals = july_df['Deal - Title'].nunique()\n",
    "\n",
    "# Adding the total expected volume, after cleaning the numbers\n",
    "july_actual_volume = (\n",
    "    july_df['Deal - Total Annual Exp. Volume']\n",
    "    .replace('[^0-9.]', '', regex=True)  # remove any stray characters\n",
    "    .astype(float)\n",
    ").sum()\n",
    "\n",
    "# Printing the summary of the current pipeline status\n",
    "print(f\"Current July pipeline: {july_actual_deals} deals, total volume £{july_actual_volume:,.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a0aab6c8-2e1e-4ae5-b1c4-0132ac39b9d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deal - Won time\n",
      "2025-03-01    3.315727e+08\n",
      "2025-04-01    1.665503e+08\n",
      "2025-05-01    4.398134e+07\n",
      "2025-06-01    1.406565e+08\n",
      "2025-07-01    1.602166e+07\n",
      "Freq: MS, Name: Deal - Total Annual Exp. Volume, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Preparing the historical volume data \n",
    "#Cleaning the volume numbers\n",
    "volume_df['Deal - Total Annual Exp. Volume'] = (\n",
    "    volume_df['Deal - Total Annual Exp. Volume']\n",
    "    .replace('[^0-9.]', '', regex=True).astype(float)\n",
    ")\n",
    "\n",
    "# Converting the date format\n",
    "volume_df['Deal - Won time'] = pd.to_datetime(volume_df['Deal - Won time'])\n",
    "\n",
    "# Grouping by month to get the monthly total volume\n",
    "volume_monthly = volume_df.groupby(volume_df['Deal - Won time'].dt.to_period('M'))['Deal - Total Annual Exp. Volume'].sum()\n",
    "volume_monthly.index = volume_monthly.index.to_timestamp()\n",
    "\n",
    "# Printing last few months to verify\n",
    "print(volume_monthly.tail())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8cd7d4cc-b29b-49db-9f0b-19121bc7ff87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deal - Won time\n",
      "2025-03-01    315\n",
      "2025-04-01    131\n",
      "2025-05-01    147\n",
      "2025-06-01    140\n",
      "2025-07-01     29\n",
      "Freq: MS, Name: Deal - Title, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Preparing the historical number of deals\n",
    "# Converting the won time dates.\n",
    "deals_df['Deal - Won time'] = pd.to_datetime(deals_df['Deal - Won time'])\n",
    "\n",
    "# Counting the different deal titles per month\n",
    "deals_monthly = deals_df.groupby(deals_df['Deal - Won time'].dt.to_period('M'))['Deal - Title'].nunique()\n",
    "deals_monthly.index = deals_monthly.index.to_timestamp()\n",
    "\n",
    "# Printing the last few months to verify\n",
    "print(deals_monthly.tail())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "af597665-2e56-493a-b97d-294288f5912a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time series forecast for July:\n",
      "- Expected volume: £145,819,869.21\n",
      "- Expected # of deals: 65.6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Jade\\AppData\\Local\\Temp\\ipykernel_23900\\2409087470.py:3: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  forecast_volume_july = model_vol.forecast(1)[0]\n",
      "C:\\Users\\Jade\\AppData\\Local\\Temp\\ipykernel_23900\\2409087470.py:6: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  forecast_deals_july = model_deals.forecast(1)[0]\n"
     ]
    }
   ],
   "source": [
    "# Forcasting July using historical trends. Building the time series forecasting models\n",
    "model_vol = ExponentialSmoothing(volume_monthly, trend='add', seasonal=None).fit()\n",
    "forecast_volume_july = model_vol.forecast(1)[0]\n",
    "\n",
    "model_deals = ExponentialSmoothing(deals_monthly, trend='add', seasonal=None).fit()\n",
    "forecast_deals_july = model_deals.forecast(1)[0]\n",
    "\n",
    "print(f\"Time series forecast for July:\")\n",
    "print(f\"- Expected volume: £{forecast_volume_july:,.2f}\")\n",
    "print(f\"- Expected # of deals: {forecast_deals_july:.1f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2590077c-2874-4744-994c-353c4cb27706",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Scaled projection based on current pace:\n",
      "- # Deals by month end: 1102.2\n",
      "- Volume by month end: £927,822,279.79\n"
     ]
    }
   ],
   "source": [
    "# Scaling the current July pipeline to estimate the end of month total i.e taking the actual data collected for the month and \n",
    "# using it to estimate what the whole month might look like if the current pace continues\n",
    "days_so_far = 9  # today's day in July\n",
    "days_in_month = 31\n",
    "\n",
    "# Scaling up based on the current run rate\n",
    "scaled_july_deals = (july_actual_deals / days_so_far) * days_in_month\n",
    "scaled_july_volume = (july_actual_volume / days_so_far) * days_in_month\n",
    "\n",
    "print(\"\\nScaled projection based on current pace:\")\n",
    "print(f\"- # Deals by month end: {scaled_july_deals:.1f}\")\n",
    "print(f\"- Volume by month end: £{scaled_july_volume:,.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d5e879ed-342c-44ba-b5ca-27f1525fa9c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "july_df = pd.read_excel(\"July Forecast cleaned.xlsx\")\n",
    "july_df = july_df[july_df['Include / Exclude'] != 'Exclude']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "57412e2a-4d19-4f91-aa0c-01b675d1194c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current July pipeline (after filtering): 290 high-confidence deals\n",
      "Total weighted # of deals: 166.4\n",
      "Total volume £228,979,630.28\n"
     ]
    }
   ],
   "source": [
    "# Updating the filtering logic using the weighted deals column. \n",
    "# Step 1: Excluding the low-confidence weighted deals (≤ 0.25)\n",
    "july_df = july_df[july_df['Weighted # Deal'] > 0.25]\n",
    "\n",
    "# Step 2: Calculating the total weighted deals\n",
    "july_weighted_deals = july_df['Weighted # Deal'].sum()\n",
    "\n",
    "# Step 3: Cleaning the volume column and calculating the total volume\n",
    "july_actual_volume = (\n",
    "    july_df['Deal - Total Annual Exp. Volume']\n",
    "    .replace('[^0-9.]', '', regex=True).astype(float)\n",
    ").sum()\n",
    "\n",
    "# Checing how many deals remain\n",
    "july_actual_deals = july_df['Deal - Title'].nunique()\n",
    "\n",
    "print(f\"Current July pipeline (after filtering): {july_actual_deals} high-confidence deals\")\n",
    "print(f\"Total weighted # of deals: {july_weighted_deals:.1f}\")\n",
    "print(f\"Total volume £{july_actual_volume:,.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d7c6b94b-69cb-4da7-84de-32535045a2b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Scaled projection based on high-confidence pipeline:\n",
      "- # Deals by month end: 573.3\n",
      "- Volume by month end: £788,707,615.41\n"
     ]
    }
   ],
   "source": [
    "# Calculating the scaled forecast \n",
    "# From todays date to the end of the month.\n",
    "days_so_far = 9\n",
    "days_in_month = 31\n",
    "\n",
    "# Scaling up both weighted deals and total volume\n",
    "scaled_july_deals = (july_weighted_deals / days_so_far) * days_in_month\n",
    "scaled_july_volume = (july_actual_volume / days_so_far) * days_in_month\n",
    "\n",
    "# Printing the scaled forecast\n",
    "print(\"\\nScaled projection based on high-confidence pipeline:\")\n",
    "print(f\"- # Deals by month end: {scaled_july_deals:.1f}\")\n",
    "print(f\"- Volume by month end: £{scaled_july_volume:,.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a02cd85e-d80c-4100-8500-97e3cdacf7ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==== FINAL BLENDED JULY FORECAST (HIGH-CONFIDENCE ONLY) ====\n",
      "Expected # deals for July: 319.4\n",
      "Expected volume for July: £467,263,742.31\n"
     ]
    }
   ],
   "source": [
    "# Creating a time series forecast by blending the scaled forecast with ARIMA forecast for a more balanced view\n",
    "final_forecast_deals = (forecast_deals_july + scaled_july_deals) / 2\n",
    "final_forecast_volume = (forecast_volume_july + scaled_july_volume) / 2\n",
    "\n",
    "# Printing results\n",
    "print(\"\\n==== FINAL BLENDED JULY FORECAST (HIGH-CONFIDENCE ONLY) ====\")\n",
    "print(f\"Expected # deals for July: {final_forecast_deals:.1f}\")\n",
    "print(f\"Expected volume for July: £{final_forecast_volume:,.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e236d9a8-1c6c-42b8-b786-341e7818f9e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   Stage  Best Case  Commitment  Worst Case  Blank\n",
      "0                Lead In       0.05        0.10        0.20   0.10\n",
      "1         Lead Qualified       0.10        0.15        0.25   0.15\n",
      "2            Opportunity       0.15        0.25        0.35   0.35\n",
      "3          Proposal Made       0.20        0.35        0.55   0.45\n",
      "4      App with Merchant       0.25        0.50        0.65   0.57\n",
      "5  Application Submitted       0.40        0.60        0.79   0.69\n"
     ]
    }
   ],
   "source": [
    "# Loading the probability table\n",
    "probability_df = pd.read_csv(\"Stage_Probability_Table.csv\")\n",
    "\n",
    "# Cleaning up the column names and values (incase theres any spaces)\n",
    "probability_df.columns = probability_df.columns.str.strip()\n",
    "probability_df[\"Stage\"] = probability_df[\"Stage\"].str.strip()\n",
    "\n",
    "print(probability_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "47600fa7-4806-4328-b7b7-e184d0501327",
   "metadata": {},
   "outputs": [],
   "source": [
    "july_df = pd.read_excel(\"July Forecast cleaned.xlsx\")\n",
    "july_df = july_df[july_df['Include / Exclude'] != 'Exclude']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ffb488db-9752-4774-9e7b-9eae926c18e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Probability-Adjusted July Forecast ===\n",
      "Adjusted expected volume: £125,937,102.84\n",
      "Adjusted expected deal count: 172.1\n"
     ]
    }
   ],
   "source": [
    "# Cleaning columns just in case\n",
    "july_df.columns = july_df.columns.str.strip()\n",
    "july_df[\"Deal - Stage\"] = july_df[\"Deal - Stage\"].str.strip()\n",
    "july_df[\"Deal - Label\"] = july_df[\"Deal - Label\"].str.strip()\n",
    "\n",
    "# Melting the probability_df to make it easier to merge\n",
    "probability_melted = probability_df.melt(id_vars=[\"Stage\"], \n",
    "                                          var_name=\"Label\", \n",
    "                                          value_name=\"Close_Probability\")\n",
    "\n",
    "# Merging the probabilities into the July dataframe\n",
    "july_with_probs = pd.merge(\n",
    "    july_df,\n",
    "    probability_melted,\n",
    "    left_on=[\"Deal - Stage\", \"Deal - Label\"],\n",
    "    right_on=[\"Stage\", \"Label\"],\n",
    "    how=\"left\"\n",
    ")\n",
    "\n",
    "# Droping rows with missing probability (warn if any)\n",
    "missing_probs = july_with_probs[\"Close_Probability\"].isna().sum()\n",
    "if missing_probs > 0:\n",
    "    print(f\"⚠️ {missing_probs} rows have missing probabilities. Check stage/label values.\")\n",
    "\n",
    "# Applying probabilities to volume and deal weighting\n",
    "july_with_probs[\"Adjusted Volume\"] = (\n",
    "    july_with_probs[\"Deal - Total Annual Exp. Volume\"]\n",
    "    .replace('[^0-9.]', '', regex=True).astype(float)\n",
    "    * july_with_probs[\"Close_Probability\"]\n",
    ")\n",
    "\n",
    "# Adjusting the weighted deal count (each deal * its probability)\n",
    "july_with_probs[\"Adjusted Deal\"] = july_with_probs[\"Close_Probability\"]\n",
    "\n",
    "# Final adjusted totals\n",
    "adjusted_volume_total = july_with_probs[\"Adjusted Volume\"].sum()\n",
    "adjusted_deal_count = july_with_probs[\"Adjusted Deal\"].sum()\n",
    "\n",
    "print(\"\\n=== Probability-Adjusted July Forecast ===\")\n",
    "print(f\"Adjusted expected volume: £{adjusted_volume_total:,.2f}\")\n",
    "print(f\"Adjusted expected deal count: {adjusted_deal_count:.1f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3597a1d3-c789-4f1b-b926-761b1b06a667",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==== FINAL BLENDED FORECAST FOR JULY ====\n",
      "Expected number of deals: 118.8\n",
      "Expected volume: £135,878,486.03\n"
     ]
    }
   ],
   "source": [
    "# Creating a blended forecast from the time series forecast (closed deals and volume from March-June)\n",
    "\n",
    "# Forecasts from each method\n",
    "# Probability adjusted July forecast\n",
    "pipeline_volume = 125_937_102.84\n",
    "pipeline_deals = 172.1\n",
    "\n",
    "# Time series forecast\n",
    "timeseries_volume = 145_819_869.21\n",
    "timeseries_deals = 65.6\n",
    "\n",
    "# Blended average forecast of both\n",
    "blended_volume = (pipeline_volume + timeseries_volume) / 2\n",
    "blended_deals = (pipeline_deals + timeseries_deals) / 2\n",
    "\n",
    "print(\"\\n==== FINAL BLENDED FORECAST FOR JULY ====\")\n",
    "print(f\"Expected number of deals: {blended_deals:.1f}\")\n",
    "print(f\"Expected volume: £{blended_volume:,.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5ea83d6b-b126-435b-a0c3-14b03822e72b",
   "metadata": {},
   "outputs": [],
   "source": [
    "july_df = pd.read_excel(\"July Forecast cleaned.xlsx\")\n",
    "july_df = july_df[july_df['Include / Exclude'] != 'Exclude']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "d185fccc-f4c4-4dec-9347-0fe9e5868a98",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Stage</th>\n",
       "      <th>Best Case</th>\n",
       "      <th>Commitment</th>\n",
       "      <th>Worst Case</th>\n",
       "      <th>Blank</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Lead In</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Lead Qualified</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Opportunity</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.35</td>\n",
       "      <td>0.35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Proposal Made</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.35</td>\n",
       "      <td>0.55</td>\n",
       "      <td>0.45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>App with Merchant</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.65</td>\n",
       "      <td>0.57</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Stage  Best Case  Commitment  Worst Case  Blank\n",
       "0            Lead In       0.05        0.10        0.20   0.10\n",
       "1     Lead Qualified       0.10        0.15        0.25   0.15\n",
       "2        Opportunity       0.15        0.25        0.35   0.35\n",
       "3      Proposal Made       0.20        0.35        0.55   0.45\n",
       "4  App with Merchant       0.25        0.50        0.65   0.57"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "probability_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "3e659cb7-f1d2-4f51-b3fc-c55db0c2f77b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Blended Platform Forecast Summary ===\n",
      "              Platform  Num_Deals  Expected_Deals Expected Volume (£)  Deal Share (%)  Volume Share (%)\n",
      "                   APT          2               1       £1,056,624.35             0.5               0.8\n",
      "              Adelante         14               8       £4,128,800.69             4.6               3.3\n",
      "             Blue Zinc          2               1          £22,800.00             0.7               0.0\n",
      "                   CSY        106              54      £58,802,575.23            31.2              46.7\n",
      "          Club Systems         11               6         £602,350.00             3.5               0.5\n",
      "Computers For Flooring          5               3       £8,220,312.44             1.5               6.5\n",
      "                 Cymba          1               1               £0.00             0.3               0.0\n",
      "                   EKM         14               7       £1,367,597.69             4.3               1.1\n",
      "           EPOS Bureau          2               1       £3,120,000.00             0.8               2.5\n",
      "                Eworks          5               3         £479,500.00             1.9               0.4\n",
      "            Felinesoft          2               1       £1,159,200.00             0.8               0.9\n",
      "                   GDS         18              11       £1,854,300.00             6.5               1.5\n",
      "               Giftpro         13               8         £213,595.23             4.8               0.2\n",
      "                 Gob2b         15               7       £3,401,574.63             4.1               2.7\n",
      "        Harbour Assist          4               3       £1,190,430.86             1.7               0.9\n",
      "      Intelligent Golf         34              19       £3,072,300.00            10.9               2.4\n",
      "            MillerTech          4               1          £16,184.20             0.6               0.0\n",
      "                   PPM          8               4          £79,100.00             2.3               0.1\n",
      "        Practice Point          3               2         £937,500.00             1.1               0.7\n",
      "               Pursuit          6               2       £2,827,500.00             1.2               2.2\n",
      "            Sellerdeck          1               0          £50,335.02             0.3               0.0\n",
      "           Swan Retail         10               4      £29,430,868.50             2.4              23.4\n",
      "                 TISSL          7               2       £2,620,000.00             1.3               2.1\n",
      "            ThinkSmart         16              11         £249,504.00             6.4               0.2\n",
      "              e-Clinic         18              11       £1,034,150.00             6.2               0.8\n"
     ]
    }
   ],
   "source": [
    "# Calculating the expected deal count and volume per platform, under each probability scenario (best case, commitment ect.)\n",
    "\n",
    "# Step 1: Melting the probability table into long format\n",
    "probability_long = probability_df.melt(\n",
    "    id_vars='Stage',\n",
    "    var_name='Label',\n",
    "    value_name='Probability'\n",
    ")\n",
    "\n",
    "\n",
    "# Step 2: No need to convert, already floats\n",
    "# But just ensuring the column is float\n",
    "probability_long['Probability'] = probability_long['Probability'].astype(float)\n",
    "\n",
    "# Step 3: Cleaning the July data\n",
    "july_df_cleaned = july_df[[\n",
    "    'Deal - Title', 'Deal - Total Annual Exp. Volume',\n",
    "    'Deal - Stage', 'Deal - Label', 'Deal - Cross-Sell Source'\n",
    "]].copy()\n",
    "\n",
    "july_df_cleaned.columns = ['Title', 'Volume', 'Stage', 'Label', 'Platform']\n",
    "\n",
    "\n",
    "# Step 4: Merging July data with long-format probabilities\n",
    "merged = pd.merge(\n",
    "    july_df_cleaned,\n",
    "    probability_long,\n",
    "    how='left',\n",
    "    left_on=['Stage', 'Label'],\n",
    "    right_on=['Stage', 'Label']\n",
    ")\n",
    "\n",
    "# Converting Volume to float (removing £ and commas)\n",
    "merged['Volume'] = merged['Volume'].astype(str).str.replace('£', '', regex=False).str.replace(',', '', regex=False).astype(float)\n",
    "\n",
    "# Step 5: Calculating expected number of deals and adjusted volume per platform\n",
    "merged['Expected_Deal'] = merged['Probability']  # each deal contributes its closing probability\n",
    "merged['Expected_Volume'] = merged['Volume'] * merged['Probability']\n",
    "\n",
    "# Grouping and calculating expected counts and volumes per platform\n",
    "platform_summary = merged.groupby('Platform').agg(\n",
    "    Num_Deals=('Title', 'count'),  # total number of July deals per platform\n",
    "    Expected_Deals=('Expected_Deal', 'sum'),  # sum of probabilities (expected number of closes)\n",
    "    Expected_Volume=('Expected_Volume', 'sum')  # weighted volume\n",
    ").reset_index()\n",
    "\n",
    "# Round Expected_Deals to nearest whole number\n",
    "platform_summary['Expected_Deals'] = platform_summary['Expected_Deals'].round(0).astype(int)\n",
    "\n",
    "# Step 6: Aggregating expected deal count and volume by platform\n",
    "platform_summary = merged.groupby('Platform').agg(\n",
    "    Num_Deals=('Title', 'count'),\n",
    "    Expected_Deals=('Expected_Deal', 'sum'),\n",
    "    Expected_Volume=('Expected_Volume', 'sum')\n",
    ").reset_index()\n",
    "\n",
    "# Step 7: Calculating deal share and volume share\n",
    "total_deals = platform_summary['Expected_Deals'].sum()\n",
    "total_volume = platform_summary['Expected_Volume'].sum()\n",
    "\n",
    "platform_summary['Deal Share (%)'] = (platform_summary['Expected_Deals'] / total_deals) * 100\n",
    "platform_summary['Volume Share (%)'] = (platform_summary['Expected_Volume'] / total_volume) * 100\n",
    "\n",
    "# Step 8: Final formatting\n",
    "platform_summary['Expected_Deals'] = platform_summary['Expected_Deals'].round(0).astype(int)\n",
    "platform_summary['Expected Volume (£)'] = platform_summary['Expected_Volume'].apply(lambda x: f\"£{x:,.2f}\")\n",
    "platform_summary['Deal Share (%)'] = platform_summary['Deal Share (%)'].round(1)\n",
    "platform_summary['Volume Share (%)'] = platform_summary['Volume Share (%)'].round(1)\n",
    "\n",
    "# Step 9: Renaming\n",
    "final_summary = platform_summary[[\n",
    "    'Platform', 'Num_Deals', 'Expected_Deals', 'Expected Volume (£)',\n",
    "    'Deal Share (%)', 'Volume Share (%)'\n",
    "]].sort_values(by='Platform')\n",
    "\n",
    "# Step 10: Display\n",
    "print(\"=== Blended Platform Forecast Summary ===\")\n",
    "print(final_summary.to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "c5e74436-92a0-4a4b-8777-cb2550f6e625",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== FINAL Blended Platform Forecast Summary (Rounded Deals) ===\n",
      "              Platform  Num_Deals  Expected_Deals Expected Volume (£)  Deal Share (%)  Volume Share (%)\n",
      "                   APT          2               1       £1,140,033.51             0.8               0.8\n",
      "              Adelante         14               5       £4,454,725.21             4.2               3.3\n",
      "             Blue Zinc          2               1          £24,599.82             0.8               0.0\n",
      "                   CSY        106              37      £63,444,407.69            31.1              46.7\n",
      "          Club Systems         11               4         £649,899.07             3.4               0.5\n",
      "Computers For Flooring          5               2       £8,869,217.92             1.7               6.5\n",
      "                 Cymba          1               0               £0.00             0.0               0.0\n",
      "                   EKM         14               5       £1,475,554.86             4.2               1.1\n",
      "           EPOS Bureau          2               1       £3,366,290.53             0.8               2.5\n",
      "                Eworks          5               2         £517,351.38             1.7               0.4\n",
      "            Felinesoft          2               1       £1,250,706.40             0.8               0.9\n",
      "                   GDS         18               8       £2,000,677.09             6.7               1.5\n",
      "               Giftpro         13               6         £230,456.28             5.0               0.2\n",
      "                 Gob2b         15               5       £3,670,092.45             4.2               2.7\n",
      "        Harbour Assist          4               2       £1,284,402.61             1.7               0.9\n",
      "      Intelligent Golf         34              13       £3,314,825.12            10.9               2.4\n",
      "            MillerTech          4               1          £17,461.77             0.8               0.0\n",
      "                   PPM          8               3          £85,344.10             2.5               0.1\n",
      "        Practice Point          3               1       £1,011,505.57             0.8               0.7\n",
      "               Pursuit          6               1       £3,050,700.79             0.8               2.2\n",
      "            Sellerdeck          1               0          £54,308.43             0.0               0.0\n",
      "           Swan Retail         10               3      £31,754,119.83             2.5              23.4\n",
      "                 TISSL          7               2       £2,826,820.89             1.7               2.1\n",
      "            ThinkSmart         16               8         £269,199.66             6.7               0.2\n",
      "              e-Clinic         18               7       £1,115,785.05             5.9               0.8\n"
     ]
    }
   ],
   "source": [
    "# Calculating the expected deal count and volume per platform, scaled to match final blended forecast \n",
    "\n",
    "# Step 1: Melting probability table into long format\n",
    "probability_long = probability_df.melt(\n",
    "    id_vars='Stage',\n",
    "    var_name='Label',\n",
    "    value_name='Probability'\n",
    ")\n",
    "\n",
    "# Step 2: Ensuring probability is float\n",
    "probability_long['Probability'] = probability_long['Probability'].astype(float)\n",
    "\n",
    "# Step 3: Cleaning July forecast data\n",
    "july_df_cleaned = july_df[[\n",
    "    'Deal - Title', 'Deal - Total Annual Exp. Volume',\n",
    "    'Deal - Stage', 'Deal - Label', 'Deal - Cross-Sell Source'\n",
    "]].copy()\n",
    "\n",
    "july_df_cleaned.columns = ['Title', 'Volume', 'Stage', 'Label', 'Platform']\n",
    "\n",
    "# Step 4: Merging with probability table\n",
    "merged = pd.merge(\n",
    "    july_df_cleaned,\n",
    "    probability_long,\n",
    "    how='left',\n",
    "    on=['Stage', 'Label']\n",
    ")\n",
    "\n",
    "# Step 5: Cleaning volume column and calculate expected metrics\n",
    "merged['Volume'] = (\n",
    "    merged['Volume'].astype(str)\n",
    "    .str.replace('£', '', regex=False)\n",
    "    .str.replace(',', '', regex=False)\n",
    "    .astype(float)\n",
    ")\n",
    "merged['Expected_Deal'] = merged['Probability']\n",
    "merged['Expected_Volume'] = merged['Volume'] * merged['Probability']\n",
    "\n",
    "# Step 6: Aggregating by platform\n",
    "platform_summary = merged.groupby('Platform').agg(\n",
    "    Num_Deals=('Title', 'count'),\n",
    "    Expected_Deals=('Expected_Deal', 'sum'),\n",
    "    Expected_Volume=('Expected_Volume', 'sum')\n",
    ").reset_index()\n",
    "\n",
    "# Step 7: Scaling to match final blended forecast totals\n",
    "blended_total_deals = 118.8\n",
    "blended_total_volume = 135_878_486.03\n",
    "\n",
    "deal_scaling_factor = blended_total_deals / platform_summary['Expected_Deals'].sum()\n",
    "volume_scaling_factor = blended_total_volume / platform_summary['Expected_Volume'].sum()\n",
    "\n",
    "platform_summary['Expected_Deals'] = (\n",
    "    platform_summary['Expected_Deals'] * deal_scaling_factor\n",
    ").round(0).astype(int)  # ← whole numbers here\n",
    "platform_summary['Expected_Volume'] = (\n",
    "    platform_summary['Expected_Volume'] * volume_scaling_factor\n",
    ")\n",
    "\n",
    "# Step 8: Recalculating % shares using rounded deals\n",
    "platform_summary['Deal Share (%)'] = (\n",
    "    platform_summary['Expected_Deals'] / platform_summary['Expected_Deals'].sum() * 100\n",
    ").round(1)\n",
    "\n",
    "platform_summary['Volume Share (%)'] = (\n",
    "    platform_summary['Expected_Volume'] / blended_total_volume * 100\n",
    ").round(1)\n",
    "\n",
    "# Step 9: Final formatting\n",
    "platform_summary['Expected Volume (£)'] = platform_summary['Expected_Volume'].apply(lambda x: f\"£{x:,.2f}\")\n",
    "\n",
    "# Step 10: Selecting and ordering columns\n",
    "final_summary = platform_summary[[\n",
    "    'Platform', 'Num_Deals', 'Expected_Deals', 'Expected Volume (£)',\n",
    "    'Deal Share (%)', 'Volume Share (%)'\n",
    "]].sort_values(by='Platform')\n",
    "\n",
    "# Step 11: Display\n",
    "print(\"=== FINAL Blended Platform Forecast Summary (Rounded Deals) ===\")\n",
    "print(final_summary.to_string(index=False))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "14e19473-67d1-4487-a910-54536f4c2337",
   "metadata": {},
   "outputs": [],
   "source": [
    "july_df = pd.read_excel(\"July Forecast cleaned.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "8a616039-0263-4740-b538-b9c052c5a8d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filtering out excluded deals\n",
    "july_df = july_df[july_df['Include / Exclude / Closed'] != 'Exclude'].copy()\n",
    "\n",
    "# Ensuring Volume is cleaned and converted to float\n",
    "\n",
    "july_df['Deal - Total Annual Exp. Volume'] = july_df['Deal - Total Annual Exp. Volume'].apply(\n",
    "    lambda x: str(x).replace('£', '').replace(',', '')\n",
    ").astype(float)\n",
    "\n",
    "# Renaming for clarity\n",
    "july_df = july_df.rename(columns={\n",
    "    'Deal - Total Annual Exp. Volume': 'Volume',\n",
    "    'Deal - Stage': 'Stage',\n",
    "    'Deal - Label': 'Label',\n",
    "    'Deal - Cross-Sell Source': 'Platform',\n",
    "    'Include / Exclude / Closed': 'Status'\n",
    "})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "07c200a3-f63e-4863-80fd-e8b4dfaafa5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Melting the probability table\n",
    "# Convert wide to long format\n",
    "probability_long = probability_df.melt(\n",
    "    id_vars='Stage',\n",
    "    var_name='Label',\n",
    "    value_name='Probability'\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "b7cb4f4c-672d-494a-aec1-1be0ec1538ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merging probabilities with open deals\n",
    "# Only deals still open (not closed)\n",
    "open_deals = july_df[july_df['Status'] != 'Closed'].copy()\n",
    "\n",
    "# Merging with probabilities\n",
    "open_merged = pd.merge(\n",
    "    open_deals,\n",
    "    probability_long,\n",
    "    how='left',\n",
    "    on=['Stage', 'Label']\n",
    ")\n",
    "\n",
    "# Calculating expected values\n",
    "open_merged['Expected_Deal'] = open_merged['Probability']\n",
    "open_merged['Expected_Volume'] = open_merged['Probability'] * open_merged['Volume']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "7197b47f-adcf-4e1a-a582-98bb6bce1a27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Treating closed deals with 100% weight\n",
    "closed_deals = july_df[july_df['Status'] == 'Closed'].copy()\n",
    "closed_deals['Expected_Deal'] = 1\n",
    "closed_deals['Expected_Volume'] = closed_deals['Volume']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "f12917db-e925-4232-9f31-afcbf75cffc2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Final Full July Forecast ===\n",
      "Expected deal count: 214.9\n",
      "Expected volume: £134,332,453.85\n"
     ]
    }
   ],
   "source": [
    "#Combining open and closed forecasts\n",
    "\n",
    "full_forecast = pd.concat([open_merged, closed_deals], ignore_index=True)\n",
    "\n",
    "# Total expected numbers\n",
    "expected_deal_count = full_forecast['Expected_Deal'].sum()\n",
    "expected_volume = full_forecast['Expected_Volume'].sum()\n",
    "\n",
    "print(\"=== Final Full July Forecast ===\")\n",
    "print(f\"Expected deal count: {expected_deal_count:.1f}\")\n",
    "print(f\"Expected volume: £{expected_volume:,.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "bb2ea30d-6068-4041-b269-3a4b6805768c",
   "metadata": {},
   "outputs": [],
   "source": [
    "closed_df = july_df[july_df['Status'] == 'Closed'].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "1c243680-2626-4893-a327-c5004340fc3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "closed_count = closed_df['Weighted # Deal'].sum()\n",
    "closed_volume = closed_df['Volume'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "f3acebab-3e92-4dd6-b2c4-946dca9cb4ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "open_count = 158.8  # from my open deals forecast\n",
    "open_volume = 91_808_181.03"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "a5ce5ee1-9566-4b10-a33f-c8d8c2b0fb1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Final July Forecast (Closed + Forecasted Open Deals) ===\n",
      "Expected total deal count: 214.8\n",
      "Expected total volume: £134,332,453.85\n"
     ]
    }
   ],
   "source": [
    "final_deal_count = closed_count + open_count\n",
    "final_volume = closed_volume + open_volume\n",
    "\n",
    "print(\"=== Final July Forecast (Closed + Forecasted Open Deals) ===\")\n",
    "print(f\"Expected total deal count: {final_deal_count:.1f}\")\n",
    "print(f\"Expected total volume: £{final_volume:,.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "53ac7982-3192-4ff0-97f3-c108a5e80dcc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Final Blended Forecast for July ===\n",
      "Expected deal count: 140.2\n",
      "Expected volume: £140,076,161.53\n"
     ]
    }
   ],
   "source": [
    "# Blended forecast using july forecast and time series forecast\n",
    "final_deal_count = closed_count + open_count      \n",
    "final_volume = closed_volume + open_volume        \n",
    "\n",
    "# Time Series Forecast\n",
    "ts_deal_count = 65.6\n",
    "ts_volume = 145_819_869.21\n",
    "\n",
    "# Blended \n",
    "blended_deals = (final_deal_count + ts_deal_count) / 2\n",
    "blended_volume = (final_volume + ts_volume) / 2\n",
    "\n",
    "print(\"=== Final Blended Forecast for July ===\")\n",
    "print(f\"Expected deal count: {blended_deals:.1f}\")\n",
    "print(f\"Expected volume: £{blended_volume:,.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "3be58ecd-f0ad-44ba-a215-4341514d35c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== FINAL Blended Platform Forecast Summary (Rounded Deals) ===\n",
      "              Platform  Num_Deals  Expected_Deals Expected Volume (£)  Deal Share (%)  Volume Share (%)\n",
      "                   APT          1               0          £61,486.46             0.0               0.0\n",
      "              Adelante         18               7       £5,716,793.25             5.0               4.1\n",
      "             Blue Zinc          5               1          £31,569.19             0.7               0.0\n",
      "                   CSY        110              44      £80,722,939.31            31.4              57.6\n",
      "          Club Systems         12               5         £903,252.63             3.6               0.6\n",
      "Computers For Flooring          5               2      £11,381,955.72             1.4               8.1\n",
      "                 Cymba          1               0               £0.00             0.0               0.0\n",
      "                   EKM         16               6       £1,893,594.25             4.3               1.4\n",
      "           EPOS Bureau          3               1       £4,319,994.17             0.7               3.1\n",
      "                Eworks          5               3         £663,922.18             2.1               0.5\n",
      "            Felinesoft          1               1         £343,938.00             0.7               0.2\n",
      "                   GDS         19               9       £2,567,488.84             6.4               1.8\n",
      "               Giftpro         15               7         £295,746.84             5.0               0.2\n",
      "                 Gob2b         20               6       £4,709,866.21             4.3               3.4\n",
      "        Harbour Assist          4               2       £2,046,290.84             1.4               1.5\n",
      "      Intelligent Golf         35              16       £4,253,948.11            11.4               3.0\n",
      "            MillerTech          2               0               £0.00             0.0               0.0\n",
      "                   PPM          9               3         £109,522.93             2.1               0.1\n",
      "        Practice Point          3               2       £1,298,075.17             1.4               0.9\n",
      "               Pursuit          6               2       £3,914,994.72             1.4               2.8\n",
      "            Sellerdeck          1               0          £69,694.55             0.0               0.0\n",
      "           Swan Retail         15               3       £8,973,498.13             2.1               6.4\n",
      "                 TISSL          9               2       £3,627,687.41             1.4               2.6\n",
      "            ThinkSmart         21               9         £345,466.61             6.4               0.2\n",
      "              e-Clinic         18               9       £1,824,436.00             6.4               1.3\n"
     ]
    }
   ],
   "source": [
    "\n",
    "probability_long = probability_df.melt(\n",
    "    id_vars='Stage',\n",
    "    var_name='Label',\n",
    "    value_name='Probability'\n",
    ")\n",
    "\n",
    "\n",
    "probability_long['Probability'] = probability_long['Probability'].astype(float)\n",
    "\n",
    "\n",
    "july_df_cleaned = july_df[[\n",
    "    'Deal - Title', 'Volume', 'Stage', 'Label', 'Platform'\n",
    "]].copy()\n",
    "\n",
    "july_df_cleaned.columns = ['Title', 'Volume', 'Stage', 'Label', 'Platform']\n",
    "\n",
    "\n",
    "merged = pd.merge(\n",
    "    july_df_cleaned,\n",
    "    probability_long,\n",
    "    how='left',\n",
    "    on=['Stage', 'Label']\n",
    ")\n",
    "\n",
    "\n",
    "merged['Volume'] = (\n",
    "    merged['Volume'].astype(str)\n",
    "    .str.replace('£', '', regex=False)\n",
    "    .str.replace(',', '', regex=False)\n",
    "    .astype(float)\n",
    ")\n",
    "\n",
    "merged['Expected_Deal'] = merged['Probability']\n",
    "merged['Expected_Volume'] = merged['Volume'] * merged['Probability']\n",
    "\n",
    "\n",
    "platform_summary = merged.groupby('Platform').agg(\n",
    "    Num_Deals=('Title', 'count'),\n",
    "    Expected_Deals=('Expected_Deal', 'sum'),\n",
    "    Expected_Volume=('Expected_Volume', 'sum')\n",
    ").reset_index()\n",
    "\n",
    "\n",
    "blended_total_deals = 140.2\n",
    "blended_total_volume = 140_076_161.53\n",
    "\n",
    "deal_scaling_factor = blended_total_deals / platform_summary['Expected_Deals'].sum()\n",
    "volume_scaling_factor = blended_total_volume / platform_summary['Expected_Volume'].sum()\n",
    "\n",
    "platform_summary['Expected_Deals'] = (\n",
    "    platform_summary['Expected_Deals'] * deal_scaling_factor\n",
    ").round(0).astype(int)\n",
    "\n",
    "platform_summary['Expected_Volume'] = (\n",
    "    platform_summary['Expected_Volume'] * volume_scaling_factor\n",
    ")\n",
    "\n",
    "\n",
    "platform_summary['Deal Share (%)'] = (\n",
    "    platform_summary['Expected_Deals'] / platform_summary['Expected_Deals'].sum() * 100\n",
    ").round(1)\n",
    "\n",
    "platform_summary['Volume Share (%)'] = (\n",
    "    platform_summary['Expected_Volume'] / blended_total_volume * 100\n",
    ").round(1)\n",
    "\n",
    "\n",
    "platform_summary['Expected Volume (£)'] = platform_summary['Expected_Volume'].apply(lambda x: f\"£{x:,.2f}\")\n",
    "\n",
    "\n",
    "final_summary = platform_summary[[\n",
    "    'Platform', 'Num_Deals', 'Expected_Deals', 'Expected Volume (£)',\n",
    "    'Deal Share (%)', 'Volume Share (%)'\n",
    "]].sort_values(by='Platform')\n",
    "\n",
    "\n",
    "print(\"=== FINAL Blended Platform Forecast Summary (Rounded Deals) ===\")\n",
    "print(final_summary.to_string(index=False))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "055abb2c-928a-4307-ac5d-b3ac792e0291",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Updated Full July Forecast ===\n",
      "Expected deal count: 214.9\n",
      "Expected volume: £134,332,453.85\n"
     ]
    }
   ],
   "source": [
    "# Filtering out excluded deals only\n",
    "filtered_df = july_df[july_df['Status'] != 'Exclude'].copy()\n",
    "\n",
    "# Preparing and cleaning probability table\n",
    "probability_long = probability_df.melt(\n",
    "    id_vars='Stage',\n",
    "    var_name='Label',\n",
    "    value_name='Probability'\n",
    ")\n",
    "probability_long['Probability'] = probability_long['Probability'].astype(float)\n",
    "\n",
    "# Merging probabilities into filtered deals\n",
    "merged = pd.merge(\n",
    "    filtered_df,\n",
    "    probability_long,\n",
    "    how='left',\n",
    "    left_on=['Stage', 'Label'],\n",
    "    right_on=['Stage', 'Label']\n",
    ")\n",
    "\n",
    "# reading Closed deals as 100% probability\n",
    "merged.loc[merged['Status'] == 'Closed', 'Probability'] = 1.0\n",
    "\n",
    "# Cleaning volume column\n",
    "merged['Volume'] = (\n",
    "    merged['Volume'].astype(str)\n",
    "    .str.replace('£', '', regex=False)\n",
    "    .str.replace(',', '', regex=False)\n",
    "    .astype(float)\n",
    ")\n",
    "\n",
    "# Calculating expected metrics\n",
    "merged['Expected_Deal'] = merged['Probability']\n",
    "merged['Expected_Volume'] = merged['Volume'] * merged['Probability']\n",
    "\n",
    "# Aggregating expected results\n",
    "total_expected_deals = merged['Expected_Deal'].sum()\n",
    "total_expected_volume = merged['Expected_Volume'].sum()\n",
    "\n",
    "# Display \n",
    "print(\"=== Updated Full July Forecast ===\")\n",
    "print(f\"Expected deal count: {total_expected_deals:.1f}\")\n",
    "print(f\"Expected volume: £{total_expected_volume:,.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "d26689de-05f5-4053-aa34-a56561b5eca9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Deal - Title', 'Volume', 'Status', 'Weighted # Deal', 'Stage', 'Label', 'Platform']\n"
     ]
    }
   ],
   "source": [
    "print(july_df.columns.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "82a7f397-1495-4509-9bae-f44827653778",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nan 'Closed']\n"
     ]
    }
   ],
   "source": [
    "print(july_df['Status'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "edc46884-854a-4f3b-8a07-5573e7f8e093",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Deal - Title</th>\n",
       "      <th>Deal - Total Annual Exp. Volume</th>\n",
       "      <th>Include / Exclude / Closed</th>\n",
       "      <th>Weighted # Deal</th>\n",
       "      <th>Deal - Stage</th>\n",
       "      <th>Deal - Label</th>\n",
       "      <th>Deal - Cross-Sell Source</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Liverpool FC deal</td>\n",
       "      <td>50000000.00</td>\n",
       "      <td>Exclude</td>\n",
       "      <td>0.35</td>\n",
       "      <td>Proposal Made</td>\n",
       "      <td>Commitment</td>\n",
       "      <td>Swan Retail</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Fraser Hart Ltd</td>\n",
       "      <td>40000000.00</td>\n",
       "      <td>Exclude</td>\n",
       "      <td>0.00</td>\n",
       "      <td>Lead Qualified</td>\n",
       "      <td>Blank</td>\n",
       "      <td>Pursuit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>RDM UK Ltd, T/A Infinity Motorcycles (16)</td>\n",
       "      <td>21291852.92</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.65</td>\n",
       "      <td>App with Merchant</td>\n",
       "      <td>Worst Case</td>\n",
       "      <td>CSY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Aqua Shard (Aqua Brit Ltd)</td>\n",
       "      <td>21000000.00</td>\n",
       "      <td>Exclude</td>\n",
       "      <td>0.00</td>\n",
       "      <td>Onboarded</td>\n",
       "      <td>Blank</td>\n",
       "      <td>Giftpro</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>T H Baker Ltd deal - EX Warrington and Wigan</td>\n",
       "      <td>20000000.00</td>\n",
       "      <td>Exclude</td>\n",
       "      <td>0.00</td>\n",
       "      <td>Proposal Made</td>\n",
       "      <td>Commitment</td>\n",
       "      <td>Pursuit</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   Deal - Title  \\\n",
       "0                             Liverpool FC deal   \n",
       "1                               Fraser Hart Ltd   \n",
       "2     RDM UK Ltd, T/A Infinity Motorcycles (16)   \n",
       "3                    Aqua Shard (Aqua Brit Ltd)   \n",
       "4  T H Baker Ltd deal - EX Warrington and Wigan   \n",
       "\n",
       "   Deal - Total Annual Exp. Volume Include / Exclude / Closed  \\\n",
       "0                      50000000.00                    Exclude   \n",
       "1                      40000000.00                    Exclude   \n",
       "2                      21291852.92                        NaN   \n",
       "3                      21000000.00                    Exclude   \n",
       "4                      20000000.00                    Exclude   \n",
       "\n",
       "   Weighted # Deal       Deal - Stage Deal - Label Deal - Cross-Sell Source  \n",
       "0             0.35      Proposal Made   Commitment              Swan Retail  \n",
       "1             0.00     Lead Qualified        Blank                  Pursuit  \n",
       "2             0.65  App with Merchant   Worst Case                      CSY  \n",
       "3             0.00          Onboarded        Blank                  Giftpro  \n",
       "4             0.00      Proposal Made   Commitment                  Pursuit  "
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "\n",
    "july_df = pd.read_excel(\"july forecast cleaned.xlsx\", engine=\"openpyxl\")\n",
    "\n",
    "# Preview the top rows\n",
    "july_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "4b82805c-3773-416c-ae33-ee9abbf6dedb",
   "metadata": {},
   "outputs": [],
   "source": [
    "july_df = july_df.rename(columns={\n",
    "    'Deal - Title': 'Title',\n",
    "    'Deal - Total Annual Exp. Volume': 'Volume',\n",
    "    'Include / Exclude / Closed': 'Status',\n",
    "    'Weighted # Deal': 'Weighted_Deal',\n",
    "    'Deal - Stage': 'Stage',\n",
    "    'Deal - Label': 'Label',\n",
    "    'Deal - Cross-Sell Source': 'Platform'\n",
    "})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "08966a7c-1d18-4238-850b-c72ba35a3874",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dropping \"Exclude\" deals\n",
    "july_df = july_df[july_df['Status'] != 'Exclude'].copy()\n",
    "\n",
    "# Handling closed deals as 100% probability\n",
    "july_df['Probability'] = july_df['Status'].apply(lambda x: 1.0 if x == 'Closed' else None)\n",
    "\n",
    "# Converting volume to float \n",
    "july_df['Volume'] = july_df['Volume'].astype(float)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "bd15340a-114b-441d-a673-7ce703eb5b94",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Melting probability table\n",
    "probability_long = probability_df.melt(\n",
    "    id_vars='Stage',\n",
    "    var_name='Label',\n",
    "    value_name='Probability'\n",
    ")\n",
    "\n",
    "# Merging for open deals only \n",
    "july_df = pd.merge(\n",
    "    july_df,\n",
    "    probability_long,\n",
    "    how='left',\n",
    "    on=['Stage', 'Label'],\n",
    "    suffixes=('', '_from_prob')\n",
    ")\n",
    "\n",
    "# Filling in open deal probabilities from table, leaving closed as 1.0\n",
    "july_df['Probability'] = july_df['Probability'].fillna(july_df['Probability_from_prob'])\n",
    "\n",
    "# Dropping helper column\n",
    "july_df.drop(columns='Probability_from_prob', inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "0e20d8de-8b98-4794-a2d9-499ebeb6d5e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calculating expected deals and volumes\n",
    "july_df['Expected_Deal'] = july_df['Probability']\n",
    "july_df['Expected_Volume'] = july_df['Volume'] * july_df['Probability']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "405a7ee8-f51a-4a6a-895f-69ec7016764c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Updated Full July Forecast ===\n",
      "Expected deal count: 214.9\n",
      "Expected volume: £134,332,453.85\n"
     ]
    }
   ],
   "source": [
    "expected_deals = july_df['Expected_Deal'].sum()\n",
    "expected_volume = july_df['Expected_Volume'].sum()\n",
    "\n",
    "print(\"=== Updated Full July Forecast ===\")\n",
    "print(f\"Expected deal count: {expected_deals:.1f}\")\n",
    "print(f\"Expected volume: £{expected_volume:,.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "346ab3f4-d624-4634-ace5-2e257b042e8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nan 'Closed']\n"
     ]
    }
   ],
   "source": [
    "print(july_df['Status'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "0e480589-3594-4c1e-9985-0dc0d2d2f7b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "july_df = pd.read_excel('july forecast cleaned.xlsx')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "47a1d83e-eb5a-456c-9051-7e7aad6b4e35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Exclude' nan 'Closed']\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(july_df['Include / Exclude / Closed'].unique())  # To verify exact values\n",
    "\n",
    "# Filter to keep only rows that are not excluded\n",
    "july_df = july_df[july_df['Include / Exclude / Closed'].str.strip().str.lower() != 'exclude'].copy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "c51c6f69-e978-4a9b-af77-da241cdfef52",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding a 'Probability' column\n",
    "july_df['Probability'] = None\n",
    "\n",
    "# Set 1.0 for closed deals\n",
    "july_df.loc[july_df['Include / Exclude / Closed'].str.strip().str.lower() == 'closed', 'Probability'] = 1.0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "8a5faa0c-43ef-4fc1-8459-5e37e2c913ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading probability table\n",
    "# Ensure 'Stage' and 'Label' columns match the July dataframe\n",
    "\n",
    "probability_long = probability_df.melt(\n",
    "    id_vars='Stage',\n",
    "    var_name='Label',\n",
    "    value_name='Probability_from_prob'\n",
    ")\n",
    "probability_long['Probability_from_prob'] = probability_long['Probability_from_prob'].astype(float)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "55d2d771-836e-41eb-8adb-cafc87f59471",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Renaming columns for merge\n",
    "july_df = july_df.rename(columns={\n",
    "    'Deal - Stage': 'Stage',\n",
    "    'Deal - Label': 'Label'\n",
    "})\n",
    "\n",
    "# Merge\n",
    "july_df = pd.merge(july_df, probability_long, on=['Stage', 'Label'], how='left')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "1be81865-d021-4c67-ba58-4645a75efbff",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Jade\\AppData\\Local\\Temp\\ipykernel_23900\\3081387688.py:1: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  july_df['Probability'] = july_df['Probability'].fillna(july_df['Probability_from_prob'])\n"
     ]
    }
   ],
   "source": [
    "\n",
    "july_df['Probability'] = july_df['Probability'].fillna(july_df['Probability_from_prob'])\n",
    "\n",
    "# Dropping the helper column\n",
    "july_df.drop(columns='Probability_from_prob', inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "2a5ee828-272b-4016-93f1-103f306fa662",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Include / Exclude / Closed\n",
      "Closed    56\n",
      "Name: count, dtype: int64\n",
      "4\n"
     ]
    }
   ],
   "source": [
    "print(july_df['Include / Exclude / Closed'].value_counts())\n",
    "print(july_df['Probability'].isna().sum()) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "75a64372-f3cd-4184-9aaa-7372684d1fdf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Deal - Title</th>\n",
       "      <th>Stage</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>353</th>\n",
       "      <td>Restaurant Michael Nadra - Primrose Hill - POS</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>354</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>355</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>356</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       Deal - Title Stage Label\n",
       "353  Restaurant Michael Nadra - Primrose Hill - POS   NaN   NaN\n",
       "354                                             NaN   NaN   NaN\n",
       "355                                             NaN   NaN   NaN\n",
       "356                                             NaN   NaN   NaN"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Showing the rows where probability is still NaN\n",
    "july_df[july_df['Probability'].isna()][['Deal - Title', 'Stage', 'Label']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "cc3c3db4-88f7-4d28-ac33-a0fbb7ab33a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dropping rows where Deal Title, Stage, and Label are all missing\n",
    "july_df = july_df[~(july_df[['Deal - Title', 'Stage', 'Label']].isna().all(axis=1))].copy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "3dd2e397-87cc-4ca6-89a2-85f0fa2aea24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "print(july_df['Probability'].isna().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "c6f279e4-8c46-488a-9644-07414b0ca985",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Deal - Title</th>\n",
       "      <th>Stage</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>353</th>\n",
       "      <td>Restaurant Michael Nadra - Primrose Hill - POS</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       Deal - Title Stage Label\n",
       "353  Restaurant Michael Nadra - Primrose Hill - POS   NaN   NaN"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "july_df[july_df['Probability'].isna()][['Deal - Title', 'Stage', 'Label']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "81985778-83d2-4bc9-ab3f-e5f045699062",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "july_df = july_df.dropna(subset=['Stage', 'Label'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "c7d5a811-e87a-4c45-9d42-b89cc2240e4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "merged = pd.merge(\n",
    "    july_df,\n",
    "    probability_long,\n",
    "    how='left',\n",
    "    on=['Stage', 'Label']\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "570f1a39-f7d7-4bc9-a56d-22934618db83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "print(july_df['Probability'].isna().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "03aa7d50-9187-412a-a4d7-9672bbba9a64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Final Full July Forecast ===\n",
      "Expected deal count: 172.8\n",
      "Expected volume: £107,103,428.06\n"
     ]
    }
   ],
   "source": [
    "july_df_filtered = july_df.copy()\n",
    "\n",
    "# Filtering out excluded deals first\n",
    "july_df_filtered = july_df[july_df['Include / Exclude / Closed'] != 'Exclude'].copy()\n",
    "\n",
    "# Rename for consistency\n",
    "july_df_filtered = july_df_filtered.rename(columns={\n",
    "    'Deal - Total Annual Exp. Volume': 'Volume',\n",
    "    'Deal - Stage': 'Stage',\n",
    "    'Deal - Label': 'Label',\n",
    "    'Deal - Cross-Sell Source': 'Platform',\n",
    " \n",
    "})\n",
    "\n",
    "\n",
    "# Assigning probability\n",
    "july_df_filtered['Probability'] = None  # new column\n",
    "\n",
    "# Assigning 1.0 to closed deals\n",
    "july_df_filtered.loc[july_df_filtered['Include / Exclude / Closed'] == 'Closed', 'Probability'] = 1.0\n",
    "\n",
    "# Merging probabilities for open deals only\n",
    "open_deals = july_df_filtered['Include / Exclude / Closed'].isna()\n",
    "july_df_filtered.loc[open_deals, 'Stage'] = july_df_filtered.loc[open_deals, 'Stage'].astype(str)\n",
    "july_df_filtered.loc[open_deals, 'Label'] = july_df_filtered.loc[open_deals, 'Label'].astype(str)\n",
    "\n",
    "# Merging with probability table \n",
    "probability_long = probability_df.melt(\n",
    "    id_vars='Stage',\n",
    "    var_name='Label',\n",
    "    value_name='Prob'\n",
    ")\n",
    "probability_long['Prob'] = probability_long['Prob'].astype(float)\n",
    "\n",
    "# Merging for open deals\n",
    "merged_probs = pd.merge(\n",
    "    july_df_filtered.loc[open_deals],\n",
    "    probability_long,\n",
    "    on=['Stage', 'Label'],\n",
    "    how='left'\n",
    ")\n",
    "\n",
    "# Put the merged probabilities back into main df\n",
    "july_df_filtered.loc[open_deals, 'Probability'] = merged_probs['Prob'].values\n",
    "\n",
    "# Cleaning volume column\n",
    "july_df_filtered['Volume'] = pd.to_numeric(\n",
    "    july_df_filtered['Volume'], errors='coerce'\n",
    ")\n",
    "\n",
    "# Calculating expected deal and expected volume\n",
    "july_df_filtered['Expected_Deal'] = july_df_filtered['Probability']\n",
    "july_df_filtered['Expected_Volume'] = july_df_filtered['Volume'] * july_df_filtered['Probability']\n",
    "\n",
    "# Final forecast totals\n",
    "expected_deal_count = july_df_filtered['Expected_Deal'].sum()\n",
    "expected_volume = july_df_filtered['Expected_Volume'].sum()\n",
    "\n",
    "# Print \n",
    "print(\"=== Final Full July Forecast ===\")\n",
    "print(f\"Expected deal count: {expected_deal_count:.1f}\")\n",
    "print(f\"Expected volume: £{expected_volume:,.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "884ad5f9-8937-4599-9cab-a6703a0f107f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Final Blended Forecast for July ===\n",
      "Expected deal count: 119.2\n",
      "Expected volume: £126,461,648.64\n"
     ]
    }
   ],
   "source": [
    "# Inputs from both models\n",
    "pipeline_deals = 172.8\n",
    "pipeline_volume = 107_103_428.06\n",
    "\n",
    "ts_deals = 65.6\n",
    "ts_volume = 145_819_869.21\n",
    "\n",
    "# Blended Forecast\n",
    "blended_deals = (pipeline_deals + ts_deals) / 2\n",
    "blended_volume = (pipeline_volume + ts_volume) / 2\n",
    "\n",
    "# Output\n",
    "print(\"=== Final Blended Forecast for July ===\")\n",
    "print(f\"Expected deal count: {blended_deals:.1f}\")\n",
    "print(f\"Expected volume: £{blended_volume:,.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "f2023189-b776-4872-b459-dba36382f901",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"['Title', 'Volume', 'Platform'] not in index\"",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[105]\u001b[39m\u001b[32m, line 10\u001b[39m\n\u001b[32m      7\u001b[39m probability_long[\u001b[33m'\u001b[39m\u001b[33mProbability\u001b[39m\u001b[33m'\u001b[39m] = probability_long[\u001b[33m'\u001b[39m\u001b[33mProbability\u001b[39m\u001b[33m'\u001b[39m].astype(\u001b[38;5;28mfloat\u001b[39m)\n\u001b[32m      9\u001b[39m \u001b[38;5;66;03m# Cleaning and rename July forecast columns\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m10\u001b[39m july_df_cleaned = \u001b[43mjuly_df\u001b[49m\u001b[43m[\u001b[49m\u001b[43m[\u001b[49m\n\u001b[32m     11\u001b[39m \u001b[43m    \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mTitle\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mVolume\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mStage\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mLabel\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mPlatform\u001b[39;49m\u001b[33;43m'\u001b[39;49m\n\u001b[32m     12\u001b[39m \u001b[43m]\u001b[49m\u001b[43m]\u001b[49m.copy()\n\u001b[32m     16\u001b[39m \u001b[38;5;66;03m# Merging with probability values\u001b[39;00m\n\u001b[32m     17\u001b[39m merged = pd.merge(\n\u001b[32m     18\u001b[39m     july_df_cleaned,\n\u001b[32m     19\u001b[39m     probability_long,\n\u001b[32m     20\u001b[39m     how=\u001b[33m'\u001b[39m\u001b[33mleft\u001b[39m\u001b[33m'\u001b[39m,\n\u001b[32m     21\u001b[39m     on=[\u001b[33m'\u001b[39m\u001b[33mStage\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mLabel\u001b[39m\u001b[33m'\u001b[39m]\n\u001b[32m     22\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python313\\site-packages\\pandas\\core\\frame.py:4113\u001b[39m, in \u001b[36mDataFrame.__getitem__\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m   4111\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m is_iterator(key):\n\u001b[32m   4112\u001b[39m         key = \u001b[38;5;28mlist\u001b[39m(key)\n\u001b[32m-> \u001b[39m\u001b[32m4113\u001b[39m     indexer = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_get_indexer_strict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcolumns\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m[\u001b[32m1\u001b[39m]\n\u001b[32m   4115\u001b[39m \u001b[38;5;66;03m# take() does not accept boolean indexers\u001b[39;00m\n\u001b[32m   4116\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(indexer, \u001b[33m\"\u001b[39m\u001b[33mdtype\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m) == \u001b[38;5;28mbool\u001b[39m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python313\\site-packages\\pandas\\core\\indexes\\base.py:6212\u001b[39m, in \u001b[36mIndex._get_indexer_strict\u001b[39m\u001b[34m(self, key, axis_name)\u001b[39m\n\u001b[32m   6209\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   6210\u001b[39m     keyarr, indexer, new_indexer = \u001b[38;5;28mself\u001b[39m._reindex_non_unique(keyarr)\n\u001b[32m-> \u001b[39m\u001b[32m6212\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_raise_if_missing\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkeyarr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindexer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis_name\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   6214\u001b[39m keyarr = \u001b[38;5;28mself\u001b[39m.take(indexer)\n\u001b[32m   6215\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(key, Index):\n\u001b[32m   6216\u001b[39m     \u001b[38;5;66;03m# GH 42790 - Preserve name from an Index\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python313\\site-packages\\pandas\\core\\indexes\\base.py:6264\u001b[39m, in \u001b[36mIndex._raise_if_missing\u001b[39m\u001b[34m(self, key, indexer, axis_name)\u001b[39m\n\u001b[32m   6261\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mNone of [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkey\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m] are in the [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00maxis_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m]\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m   6263\u001b[39m not_found = \u001b[38;5;28mlist\u001b[39m(ensure_index(key)[missing_mask.nonzero()[\u001b[32m0\u001b[39m]].unique())\n\u001b[32m-> \u001b[39m\u001b[32m6264\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnot_found\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m not in index\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[31mKeyError\u001b[39m: \"['Title', 'Volume', 'Platform'] not in index\""
     ]
    }
   ],
   "source": [
    "# Melting probability table into long format\n",
    "probability_long = probability_df.melt(\n",
    "    id_vars='Stage',\n",
    "    var_name='Label',\n",
    "    value_name='Probability'\n",
    ")\n",
    "probability_long['Probability'] = probability_long['Probability'].astype(float)\n",
    "\n",
    "# Cleaning and rename July forecast columns\n",
    "july_df_cleaned = july_df[[\n",
    "    'Title', 'Volume', 'Stage', 'Label', 'Platform'\n",
    "]].copy()\n",
    "\n",
    "\n",
    "\n",
    "# Merging with probability values\n",
    "merged = pd.merge(\n",
    "    july_df_cleaned,\n",
    "    probability_long,\n",
    "    how='left',\n",
    "    on=['Stage', 'Label']\n",
    ")\n",
    "\n",
    "# Cleaning volume \n",
    "merged['Volume'] = (\n",
    "    merged['Volume'].astype(str)\n",
    "    .str.replace('£', '', regex=False)\n",
    "    .str.replace(',', '', regex=False)\n",
    "    .astype(float)\n",
    ")\n",
    "merged['Expected_Deal'] = merged['Probability']\n",
    "merged['Expected_Volume'] = merged['Volume'] * merged['Probability']\n",
    "\n",
    "# Grouping by platform\n",
    "platform_summary = merged.groupby('Platform').agg(\n",
    "    Num_Deals=('Title', 'count'),\n",
    "    Expected_Deals=('Expected_Deal', 'sum'),\n",
    "    Expected_Volume=('Expected_Volume', 'sum')\n",
    ").reset_index()\n",
    "\n",
    "# Scaling to match final blended forecast\n",
    "blended_total_deals = 119.2\n",
    "blended_total_volume = 126_461_648.64\n",
    "\n",
    "deal_scaling_factor = blended_total_deals / platform_summary['Expected_Deals'].sum()\n",
    "volume_scaling_factor = blended_total_volume / platform_summary['Expected_Volume'].sum()\n",
    "\n",
    "platform_summary['Expected_Deals'] = (\n",
    "    platform_summary['Expected_Deals'] * deal_scaling_factor\n",
    ").round(0).astype(int)\n",
    "platform_summary['Expected_Volume'] = (\n",
    "    platform_summary['Expected_Volume'] * volume_scaling_factor\n",
    ")\n",
    "\n",
    "# share percentages\n",
    "platform_summary['Deal Share (%)'] = (\n",
    "    platform_summary['Expected_Deals'] / platform_summary['Expected_Deals'].sum() * 100\n",
    ").round(1)\n",
    "\n",
    "platform_summary['Volume Share (%)'] = (\n",
    "    platform_summary['Expected_Volume'] / blended_total_volume * 100\n",
    ").round(1)\n",
    "\n",
    "# Format \n",
    "platform_summary['Expected Volume (£)'] = platform_summary['Expected_Volume'].apply(\n",
    "    lambda x: f\"£{x:,.2f}\"\n",
    ")\n",
    "\n",
    "# Final table\n",
    "final_summary = platform_summary[[\n",
    "    'Platform', 'Num_Deals', 'Expected_Deals', 'Expected Volume (£)',\n",
    "    'Deal Share (%)', 'Volume Share (%)'\n",
    "]].sort_values(by='Platform')\n",
    "\n",
    "# Display\n",
    "print(\"=== FINAL Blended Platform Forecast Summary ) ===\")\n",
    "print(final_summary.to_string(index=False))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "9f64e04b-8992-428c-bd90-548c7c565963",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Deal - Title', 'Deal - Total Annual Exp. Volume', 'Include / Exclude / Closed', 'Weighted # Deal', 'Stage', 'Label', 'Deal - Cross-Sell Source', 'Probability']\n"
     ]
    }
   ],
   "source": [
    "print(july_df.columns.tolist())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "bf5a707b-bbac-4777-a71b-a9ce377548f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== FINAL Blended Platform Forecast Summary (Rounded Deals) ===\n",
      "              Platform  Num_Deals  Expected_Deals Expected Volume (£)  Deal Share (%)  Volume Share (%)\n",
      "                   APT          1               0          £52,433.21             0.0               0.0\n",
      "              Adelante         14               6       £4,909,488.91             5.1               3.9\n",
      "             Blue Zinc          2               1          £26,920.95             0.8               0.0\n",
      "                   CSY        104              38      £73,921,517.24            32.2              58.5\n",
      "          Club Systems         11               5         £829,295.01             4.2               0.7\n",
      "Computers For Flooring          5               2      £10,378,773.82             1.7               8.2\n",
      "                 Cymba          1               0               £0.00             0.0               0.0\n",
      "                   EKM         14               5       £1,614,781.73             4.2               1.3\n",
      "           EPOS Bureau          2               1       £3,683,918.91             0.8               2.9\n",
      "                Eworks          5               2         £566,166.38             1.7               0.4\n",
      "            Felinesoft          1               0         £293,296.62             0.0               0.2\n",
      "                   GDS         18               8       £2,189,452.19             6.8               1.7\n",
      "               Giftpro         13               6         £252,201.12             5.1               0.2\n",
      "                 Gob2b         15               5       £4,025,537.00             4.2               3.2\n",
      "        Harbour Assist          4               2       £2,126,844.82             1.7               1.7\n",
      "      Intelligent Golf         34              13       £3,627,597.46            11.0               2.9\n",
      "            MillerTech          2               0               £0.00             0.0               0.0\n",
      "                   PPM          8               3          £93,396.79             2.5               0.1\n",
      "        Practice Point          3               1       £1,106,946.79             0.8               0.9\n",
      "               Pursuit          6               1       £3,338,551.51             0.8               2.6\n",
      "            Sellerdeck          1               0          £59,432.73             0.0               0.0\n",
      "           Swan Retail          7               2       £7,652,241.67             1.7               6.1\n",
      "                 TISSL          7               2       £3,093,547.29             1.7               2.4\n",
      "            ThinkSmart         16               8         £301,920.77             6.8               0.2\n",
      "              e-Clinic         17               7       £2,317,385.72             5.9               1.8\n"
     ]
    }
   ],
   "source": [
    "# Melting probability table to long format\n",
    "probability_long = probability_df.melt(\n",
    "    id_vars='Stage',\n",
    "    var_name='Label',\n",
    "    value_name='Probability'\n",
    ")\n",
    "probability_long['Probability'] = probability_long['Probability'].astype(float)\n",
    "\n",
    "# Cleaning and prepare July forecast data\n",
    "july_df_cleaned = july_df[[\n",
    "    'Deal - Title', 'Deal - Total Annual Exp. Volume',\n",
    "    'Stage', 'Label', 'Deal - Cross-Sell Source', 'Probability'\n",
    "]].copy()\n",
    "\n",
    "# Renaming columns \n",
    "july_df_cleaned.columns = ['Title', 'Volume', 'Stage', 'Label', 'Platform', 'Probability']\n",
    "\n",
    "# Assigning 100% probability to closed deals, and use probability table for open deals\n",
    "is_closed = july_df['Include / Exclude / Closed'] == 'Closed'\n",
    "is_excluded = july_df['Include / Exclude / Closed'] == 'Exclude'\n",
    "is_open = ~is_closed & ~is_excluded\n",
    "\n",
    "# For open deals: merging probability from probability table\n",
    "merged_probs = pd.merge(\n",
    "    july_df_cleaned.loc[is_open, ['Stage', 'Label']],\n",
    "    probability_long,\n",
    "    how='left',\n",
    "    on=['Stage', 'Label']\n",
    ")\n",
    "\n",
    "july_df_cleaned.loc[is_closed, 'Probability'] = 1.0\n",
    "july_df_cleaned.loc[is_excluded, 'Probability'] = 0.0\n",
    "july_df_cleaned.loc[is_open, 'Probability'] = merged_probs['Probability'].values\n",
    "\n",
    "# Cleaning volume\n",
    "july_df_cleaned['Volume'] = pd.to_numeric(july_df_cleaned['Volume'], errors='coerce')\n",
    "\n",
    "# Step 5: Calculate expected values\n",
    "july_df_cleaned['Expected_Deals'] = july_df_cleaned['Probability']\n",
    "july_df_cleaned['Expected_Volume'] = july_df_cleaned['Volume'] * july_df_cleaned['Probability']\n",
    "\n",
    "# Grouping by platform\n",
    "platform_summary = july_df_cleaned.groupby('Platform').agg(\n",
    "    Num_Deals=('Title', 'count'),\n",
    "    Expected_Deals=('Expected_Deals', 'sum'),\n",
    "    Expected_Volume=('Expected_Volume', 'sum')\n",
    ").reset_index()\n",
    "\n",
    "# Step 7: Scale to match your final blended forecast totals\n",
    "# Use your specified final numbers here:\n",
    "blended_total_deals = 119.2\n",
    "blended_total_volume =  126_461_648.64\n",
    "\n",
    "deal_scaling = blended_total_deals / platform_summary['Expected_Deals'].sum()\n",
    "vol_scaling = blended_total_volume / platform_summary['Expected_Volume'].sum()\n",
    "\n",
    "platform_summary['Expected_Deals'] = (platform_summary['Expected_Deals'] * deal_scaling).round(0).astype(int)\n",
    "platform_summary['Expected_Volume'] = platform_summary['Expected_Volume'] * vol_scaling\n",
    "\n",
    "\n",
    "platform_summary['Deal Share (%)'] = (\n",
    "    platform_summary['Expected_Deals'] / platform_summary['Expected_Deals'].sum() * 100\n",
    ").round(1)\n",
    "\n",
    "platform_summary['Volume Share (%)'] = (\n",
    "    platform_summary['Expected_Volume'] / blended_total_volume * 100\n",
    ").round(1)\n",
    "\n",
    "# Format volume \n",
    "platform_summary['Expected Volume (£)'] = platform_summary['Expected_Volume'].apply(lambda x: f\"£{x:,.2f}\")\n",
    "\n",
    "# Final formatting\n",
    "final_summary = platform_summary[[\n",
    "    'Platform', 'Num_Deals', 'Expected_Deals', 'Expected Volume (£)',\n",
    "    'Deal Share (%)', 'Volume Share (%)'\n",
    "]].sort_values(by='Platform')\n",
    "\n",
    "#  Display\n",
    "print(\"=== FINAL Blended Platform Forecast Summary (Rounded Deals) ===\")\n",
    "print(final_summary.to_string(index=False))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "92f04efd-4950-40f2-aae6-65c16370bf32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== FINAL Blended Platform Forecast Summary (Rounded Deals) ===\n",
      "              Platform  Num_Deals  Expected_Deals Expected Volume (£)  Deal Share (%)  Volume Share (%)\n",
      "                   APT          1               0               £0.00             0.0               0.0\n",
      "              Adelante         14               6       £4,909,488.91             5.1               3.9\n",
      "             Blue Zinc          2               1          £26,920.95             0.8               0.0\n",
      "                   CSY        104              38      £73,921,517.24            32.2              58.6\n",
      "          Club Systems         11               5         £829,295.01             4.2               0.7\n",
      "Computers For Flooring          5               2      £10,378,773.82             1.7               8.2\n",
      "                 Cymba          1               0               £0.00             0.0               0.0\n",
      "                   EKM         14               5       £1,614,781.73             4.2               1.3\n",
      "           EPOS Bureau          2               1       £3,683,918.91             0.8               2.9\n",
      "                Eworks          5               2         £566,166.38             1.7               0.4\n",
      "            Felinesoft          1               0               £0.00             0.0               0.0\n",
      "                   GDS         18               8       £2,189,452.19             6.8               1.7\n",
      "               Giftpro         13               6         £252,201.12             5.1               0.2\n",
      "                 Gob2b         15               5       £4,025,537.00             4.2               3.2\n",
      "        Harbour Assist          4               2       £2,126,844.82             1.7               1.7\n",
      "      Intelligent Golf         34              13       £3,627,597.46            11.0               2.9\n",
      "            MillerTech          2               0               £0.00             0.0               0.0\n",
      "                   PPM          8               3          £93,396.79             2.5               0.1\n",
      "        Practice Point          3               1       £1,106,946.79             0.8               0.9\n",
      "               Pursuit          6               1       £3,338,551.51             0.8               2.6\n",
      "            Sellerdeck          1               0          £59,432.73             0.0               0.0\n",
      "           Swan Retail          7               2       £7,652,241.67             1.7               6.1\n",
      "                 TISSL          7               2       £3,093,547.29             1.7               2.5\n",
      "            ThinkSmart         16               8         £301,920.77             6.8               0.2\n",
      "              e-Clinic         17               7       £2,317,385.72             5.9               1.8\n"
     ]
    }
   ],
   "source": [
    "# Drop excluded deals\n",
    "july_df = july_df[~(july_df['Include / Exclude / Closed'].str.lower() == 'exclude')].copy()\n",
    "\n",
    "\n",
    "# Melting probability table to long format\n",
    "probability_long = probability_df.melt(\n",
    "    id_vars='Stage',\n",
    "    var_name='Label',\n",
    "    value_name='Probability'\n",
    ")\n",
    "probability_long['Probability'] = probability_long['Probability'].astype(float)\n",
    "\n",
    "# Cleaning and prepare July forecast data\n",
    "july_df_cleaned = july_df[[\n",
    "    'Deal - Title', 'Deal - Total Annual Exp. Volume',\n",
    "    'Stage', 'Label', 'Deal - Cross-Sell Source', 'Probability'\n",
    "]].copy()\n",
    "\n",
    "# Renaming columns \n",
    "july_df_cleaned.columns = ['Title', 'Volume', 'Stage', 'Label', 'Platform', 'Probability']\n",
    "\n",
    "# Assigning 100% probability to closed deals, and use probability table for open deals\n",
    "is_closed = july_df['Include / Exclude / Closed'] == 'Closed'\n",
    "is_excluded = july_df['Include / Exclude / Closed'] == 'Exclude'\n",
    "is_open = ~is_closed & ~is_excluded\n",
    "\n",
    "# For open deals: merging probability from probability table\n",
    "merged_probs = pd.merge(\n",
    "    july_df_cleaned.loc[is_open, ['Stage', 'Label']],\n",
    "    probability_long,\n",
    "    how='left',\n",
    "    on=['Stage', 'Label']\n",
    ")\n",
    "\n",
    "july_df_cleaned.loc[is_closed, 'Probability'] = 1.0\n",
    "july_df_cleaned = july_df_cleaned[~is_excluded].copy()\n",
    "july_df_cleaned.loc[is_open, 'Probability'] = merged_probs['Probability'].values\n",
    "\n",
    "# Cleaning volume\n",
    "july_df_cleaned['Volume'] = pd.to_numeric(july_df_cleaned['Volume'], errors='coerce')\n",
    "\n",
    "# Step 5: Calculate expected values\n",
    "july_df_cleaned['Expected_Deals'] = july_df_cleaned['Probability']\n",
    "july_df_cleaned['Expected_Volume'] = july_df_cleaned['Volume'] * july_df_cleaned['Probability']\n",
    "\n",
    "# Grouping by platform\n",
    "platform_summary = july_df_cleaned.groupby('Platform').agg(\n",
    "    Num_Deals=('Title', 'count'),\n",
    "    Expected_Deals=('Expected_Deals', 'sum'),\n",
    "    Expected_Volume=('Expected_Volume', 'sum')\n",
    ").reset_index()\n",
    "\n",
    "# Step 7: Scale to match your final blended forecast totals\n",
    "# Use your specified final numbers here:\n",
    "blended_total_deals = 119.2\n",
    "blended_total_volume =  126_461_648.64\n",
    "\n",
    "deal_scaling = blended_total_deals / platform_summary['Expected_Deals'].sum()\n",
    "vol_scaling = blended_total_volume / platform_summary['Expected_Volume'].sum()\n",
    "\n",
    "platform_summary['Expected_Deals'] = (platform_summary['Expected_Deals'] * deal_scaling).round(0).astype(int)\n",
    "platform_summary['Expected_Volume'] = platform_summary['Expected_Volume'] * vol_scaling\n",
    "\n",
    "\n",
    "platform_summary['Deal Share (%)'] = (\n",
    "    platform_summary['Expected_Deals'] / platform_summary['Expected_Deals'].sum() * 100\n",
    ").round(1)\n",
    "\n",
    "platform_summary['Volume Share (%)'] = (\n",
    "    platform_summary['Expected_Volume'] / blended_total_volume * 100\n",
    ").round(1)\n",
    "\n",
    "\n",
    "excluded_platforms = ['APT', 'Felinesoft', 'MillerTech']\n",
    "\n",
    "platform_summary.loc[\n",
    "    platform_summary['Platform'].isin(excluded_platforms),\n",
    "    ['Expected_Deals', 'Expected_Volume']\n",
    "] = 0\n",
    "\n",
    "# Recalculate % shares after zeroing out\n",
    "total_deals = platform_summary['Expected_Deals'].sum()\n",
    "total_volume = platform_summary['Expected_Volume'].sum()\n",
    "\n",
    "platform_summary['Expected_Deals'] = platform_summary['Expected_Deals'].astype(int)\n",
    "platform_summary['Expected Volume (£)'] = platform_summary['Expected_Volume'].apply(lambda x: f\"£{x:,.2f}\")\n",
    "\n",
    "platform_summary['Deal Share (%)'] = (\n",
    "    platform_summary['Expected_Deals'] / total_deals * 100\n",
    ").round(1)\n",
    "\n",
    "platform_summary['Volume Share (%)'] = (\n",
    "    platform_summary['Expected_Volume'] / total_volume * 100\n",
    ").round(1)\n",
    "\n",
    "\n",
    "# Format volume \n",
    "platform_summary['Expected Volume (£)'] = platform_summary['Expected_Volume'].apply(lambda x: f\"£{x:,.2f}\")\n",
    "\n",
    "# Final formatting\n",
    "final_summary = platform_summary[[\n",
    "    'Platform', 'Num_Deals', 'Expected_Deals', 'Expected Volume (£)',\n",
    "    'Deal Share (%)', 'Volume Share (%)'\n",
    "]].sort_values(by='Platform')\n",
    "\n",
    "\n",
    "platform_summary.loc[\n",
    "    platform_summary['Platform'].isin(['APT', 'Felinesoft', 'MillerTech']),\n",
    "    ['Expected_Deals', 'Expected_Volume']\n",
    "] = 0\n",
    "\n",
    "\n",
    "platform_summary['Expected_Deals'] = platform_summary['Expected_Deals'].astype(int)\n",
    "platform_summary['Expected Volume (£)'] = platform_summary['Expected_Volume'].apply(lambda x: f\"£{x:,.2f}\")\n",
    "\n",
    "platform_summary['Deal Share (%)'] = (\n",
    "    platform_summary['Expected_Deals'] / platform_summary['Expected_Deals'].sum() * 100\n",
    ").round(1)\n",
    "\n",
    "platform_summary['Volume Share (%)'] = (\n",
    "    platform_summary['Expected_Volume'] / blended_total_volume * 100\n",
    ").round(1)\n",
    "\n",
    "\n",
    "#  Display\n",
    "print(\"=== FINAL Blended Platform Forecast Summary (Rounded Deals) ===\")\n",
    "print(final_summary.to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "ace2a411-d112-4d1c-805d-226b153a3ccc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "b2aa981c-b413-4122-aeac-f364384353b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the new Excel files\n",
    "volume_df = pd.read_excel('YTD Forecast Volume.xlsx')\n",
    "deals_df = pd.read_excel('YTD Forecast Deals.xlsx')\n",
    "\n",
    "# Cleaning the column names (removing % and converting to numeric)\n",
    "for df in [volume_df, deals_df]:\n",
    "    df['YTD'] = df['YTD'].astype(str).str.replace('%', '').astype(float)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "ed571eef-dfdb-4e7c-81b1-aba907938ad1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of reps and their platforms\n",
    "rep_platforms = {\n",
    "    'Steve': ['Blue Zinc', 'ThinkSmart', 'CSY'],\n",
    "    'Iman': ['Harbour Assist', 'Cymba', 'Giftpro & GVS', 'CSY'],\n",
    "    'Nico': ['CSY', 'Pursuit', 'TISSL'],\n",
    "    'Anna': ['Club Systems', 'Intelligentgolf', 'Computers For Flooring'],\n",
    "    'Amanda': ['Swan', 'Gob2b', 'EPOS Bureau']\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "fa1f7ad7-c049-45c1-9b9d-3d639969a87d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculating YTD forecast accuracy per sales rep\n",
    "\n",
    "def calc_rep_accuracy(forecast_df, rep_platforms):\n",
    "    rep_results = []\n",
    "\n",
    "    for rep, platforms in rep_platforms.items():\n",
    "        # Filtering rows in the DataFrame that match the rep's platforms\n",
    "        df_subset = forecast_df[forecast_df['Platform'].isin(platforms)]\n",
    "        ytd_values = df_subset['YTD']\n",
    "\n",
    "        # Calculating average deviation\n",
    "        avg_deviation = ytd_values.mean() if not ytd_values.empty else 0\n",
    "        rep_results.append({'Sales Rep': rep, 'Avg YTD % Difference': avg_deviation})\n",
    "\n",
    "    return pd.DataFrame(rep_results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "e5498b22-d329-4353-b8b0-665241a24451",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Running calculations for volume and deals\n",
    "\n",
    "rep_volume_accuracy = calc_rep_accuracy(volume_df, rep_platforms)\n",
    "rep_deals_accuracy = calc_rep_accuracy(deals_df, rep_platforms)\n",
    "\n",
    "# Adding a label \n",
    "rep_volume_accuracy['Metric'] = 'Volume'\n",
    "rep_deals_accuracy['Metric'] = 'Deals'\n",
    "\n",
    "# Combining into one summary table\n",
    "final_accuracy_summary = pd.concat([rep_volume_accuracy, rep_deals_accuracy])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "854a1ad2-7d88-4a9d-9ad9-ae315aa88fd6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Sales Rep Forecast Accuracy Summary ===\n",
      "Metric     Deals  Volume\n",
      "Sales Rep               \n",
      "Amanda       0.1     0.0\n",
      "Anna         0.2     0.4\n",
      "Iman         0.6     0.0\n",
      "Nico         0.2     0.5\n",
      "Steve       -0.0     0.2\n"
     ]
    }
   ],
   "source": [
    "# Display\n",
    "\n",
    "print(\"=== Sales Rep Forecast Accuracy Summary ===\")\n",
    "print(final_accuracy_summary.pivot(index='Sales Rep', columns='Metric', values='Avg YTD % Difference').round(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "fcedf4da-ef20-48b8-bcc5-331edd61a3ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Time Series Forecast for August 2025 ===\n",
      "Expected volume: £109,024,597.63\n",
      "Expected number of deals: 65.9\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from statsmodels.tsa.holtwinters import ExponentialSmoothing\n",
    "\n",
    "# Volume data\n",
    "volume_data = {\n",
    "    '2025-03-01': 331_572_700,\n",
    "    '2025-04-01': 166_550_300,\n",
    "    '2025-05-01': 43_981_340,\n",
    "    '2025-06-01': 140_656_500,\n",
    "    '2025-07-01': 139_852_462\n",
    "}\n",
    "\n",
    "# Deal data\n",
    "deal_data = {\n",
    "    '2025-03-01': 315,\n",
    "    '2025-04-01': 131,\n",
    "    '2025-05-01': 147,\n",
    "    '2025-06-01': 140,\n",
    "    '2025-07-01': 132\n",
    "}\n",
    "\n",
    "# Converting to time series\n",
    "volume_series = pd.Series(volume_data)\n",
    "volume_series.index = pd.to_datetime(volume_series.index)\n",
    "volume_series = volume_series.asfreq('MS')\n",
    "\n",
    "deal_series = pd.Series(deal_data)\n",
    "deal_series.index = pd.to_datetime(deal_series.index)\n",
    "deal_series = deal_series.asfreq('MS')\n",
    "\n",
    "# Holt-Winters model for Volume\n",
    "volume_model = ExponentialSmoothing(volume_series, trend='additive', seasonal=None)\n",
    "volume_fit = volume_model.fit()\n",
    "volume_forecast = volume_fit.forecast(1)\n",
    "\n",
    "# Holt-Winters model for Deal Count\n",
    "deal_model = ExponentialSmoothing(deal_series, trend='additive', seasonal=None)\n",
    "deal_fit = deal_model.fit()\n",
    "deal_forecast = deal_fit.forecast(1)\n",
    "\n",
    "# Results\n",
    "forecasted_volume = volume_forecast.iloc[0]\n",
    "forecasted_deals = deal_forecast.iloc[0]\n",
    "\n",
    "print(\"=== Time Series Forecast for August 2025 ===\")\n",
    "print(f\"Expected volume: £{forecasted_volume:,.2f}\")\n",
    "print(f\"Expected number of deals: {forecasted_deals:.1f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "c2a1f9b9-778a-447c-bd6b-0e4ec05a8371",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Time Series Forecast for August 2025 ===\n",
      "Expected volume: £102,289,683.58\n",
      "Expected number of deals: 66.7\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from statsmodels.tsa.holtwinters import ExponentialSmoothing\n",
    "\n",
    "# Volume data\n",
    "volume_data = {\n",
    "    '2025-03-01': 331_572_700,\n",
    "    '2025-04-01': 166_550_300,\n",
    "    '2025-05-01': 43_981_340,\n",
    "    '2025-06-01': 140_656_500,\n",
    "    '2025-07-01': 154_952_461\n",
    "}\n",
    "\n",
    "# Deal data\n",
    "deal_data = {\n",
    "    '2025-03-01': 315,\n",
    "    '2025-04-01': 131,\n",
    "    '2025-05-01': 147,\n",
    "    '2025-06-01': 140,\n",
    "    '2025-07-01': 133\n",
    "}\n",
    "\n",
    "# Converting to time series\n",
    "volume_series = pd.Series(volume_data)\n",
    "volume_series.index = pd.to_datetime(volume_series.index)\n",
    "volume_series = volume_series.asfreq('MS')\n",
    "\n",
    "deal_series = pd.Series(deal_data)\n",
    "deal_series.index = pd.to_datetime(deal_series.index)\n",
    "deal_series = deal_series.asfreq('MS')\n",
    "\n",
    "# Holt-Winters model for Volume\n",
    "volume_model = ExponentialSmoothing(volume_series, trend='additive', seasonal=None)\n",
    "volume_fit = volume_model.fit()\n",
    "volume_forecast = volume_fit.forecast(1)\n",
    "\n",
    "# Holt-Winters model for Deal Count\n",
    "deal_model = ExponentialSmoothing(deal_series, trend='additive', seasonal=None)\n",
    "deal_fit = deal_model.fit()\n",
    "deal_forecast = deal_fit.forecast(1)\n",
    "\n",
    "# Results\n",
    "forecasted_volume = volume_forecast.iloc[0]\n",
    "forecasted_deals = deal_forecast.iloc[0]\n",
    "\n",
    "print(\"=== Time Series Forecast for August 2025 ===\")\n",
    "print(f\"Expected volume: £{forecasted_volume:,.2f}\")\n",
    "print(f\"Expected number of deals: {forecasted_deals:.1f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "632b24e8-c07d-4f15-958f-0957c07e0d93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 4 rows have missing probabilities. Please check the Stage/Label combinations.\n",
      "\n",
      "==== Pipeline FORECAST FOR AUGUST ====\n",
      "Expected number of deals: 187.3\n",
      "Expected volume: £153,109,866.28\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Loading the August pipeline spreadsheet\n",
    "august_df = pd.read_excel(\"Exp Deals to Close August 2025.xlsx\")\n",
    "\n",
    "# Cleaning column names\n",
    "august_df.columns = august_df.columns.str.strip()\n",
    "august_df[\"Deal - Stage\"] = august_df[\"Deal - Stage\"].astype(str).str.strip()\n",
    "august_df[\"Deal - Label\"] = august_df[\"Deal - Label\"].astype(str).str.strip()\n",
    "\n",
    "# Creating the probability matrix \n",
    "probability_data = {\n",
    "    \"Stage\": [\n",
    "        \"Lead In\", \"Lead Qualified\", \"Opportunity\", \"Proposal Made\", \"App with Merchant\", \"Application Submitted\"\n",
    "    ],\n",
    "    \"Best Case\": [0.05, 0.10, 0.15, 0.20, 0.25, 0.40],\n",
    "    \"Commitment\": [0.10, 0.15, 0.25, 0.35, 0.50, 0.60],\n",
    "    \"Worst Case\": [0.20, 0.25, 0.35, 0.55, 0.65, 0.79],\n",
    "    \"Blank\": [0.10, 0.15, 0.35, 0.45, 0.57, 0.69]\n",
    "}\n",
    "probability_df = pd.DataFrame(probability_data)\n",
    "\n",
    "# Melting the probability matrix for easier merging\n",
    "probability_melted = probability_df.melt(\n",
    "    id_vars=[\"Stage\"], \n",
    "    var_name=\"Label\", \n",
    "    value_name=\"Close_Probability\"\n",
    ")\n",
    "\n",
    "# SMerging probabilities into the August pipeline\n",
    "august_with_probs = pd.merge(\n",
    "    august_df,\n",
    "    probability_melted,\n",
    "    left_on=[\"Deal - Stage\", \"Deal - Label\"],\n",
    "    right_on=[\"Stage\", \"Label\"],\n",
    "    how=\"left\"\n",
    ")\n",
    "\n",
    "# Warn about any missing matches\n",
    "missing_probs = august_with_probs[\"Close_Probability\"].isna().sum()\n",
    "if missing_probs > 0:\n",
    "    print(f\"⚠️ {missing_probs} rows have missing probabilities. Please check the Stage/Label combinations.\")\n",
    "\n",
    "# Cleaning volume column and calculate adjusted values\n",
    "august_with_probs[\"Deal - Total Annual Exp. Volume\"] = (\n",
    "    august_with_probs[\"Deal - Total Annual Exp. Volume\"]\n",
    "    .astype(str)\n",
    "    .str.replace(\"GBP\", \"\", regex=False)\n",
    "    .str.replace(\",\", \"\")\n",
    "    .str.strip()\n",
    "    .replace('', '0')\n",
    "    .astype(float)\n",
    ")\n",
    "\n",
    "# Applying probability to volume and deal count\n",
    "august_with_probs[\"Adjusted Volume\"] = (\n",
    "    august_with_probs[\"Deal - Total Annual Exp. Volume\"] * august_with_probs[\"Close_Probability\"]\n",
    ")\n",
    "august_with_probs[\"Adjusted Deal\"] = august_with_probs[\"Close_Probability\"]\n",
    "\n",
    "# Final totals\n",
    "adjusted_volume_total = august_with_probs[\"Adjusted Volume\"].sum()\n",
    "adjusted_deal_count = august_with_probs[\"Adjusted Deal\"].sum()\n",
    "\n",
    "# Output\n",
    "print(\"\\n==== Pipeline FORECAST FOR AUGUST ====\")\n",
    "print(f\"Expected number of deals: {adjusted_deal_count:.1f}\")\n",
    "print(f\"Expected volume: £{adjusted_volume_total:,.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "6b108314-71b5-4ac4-bab4-66ea1aa83b25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==== FINAL BLENDED FORECAST FOR AUGUST ====\n",
      "Expected number of deals: 127.0\n",
      "Expected volume: £127,699,774.93\n"
     ]
    }
   ],
   "source": [
    "# Inputs from your pipeline forecast\n",
    "pipeline_expected_volume = 153_109_866.28\n",
    "pipeline_expected_deals = 187.3\n",
    "\n",
    "# Inputs from your time series forecast\n",
    "ts_expected_volume = 102_289_683.58\n",
    "ts_expected_deals = 66.7\n",
    "\n",
    "# Simple average (50/50 weighting)\n",
    "blended_volume = (pipeline_expected_volume + ts_expected_volume) / 2\n",
    "blended_deals = (pipeline_expected_deals + ts_expected_deals) / 2\n",
    "\n",
    "# Output the blended forecast\n",
    "print(\"\\n==== FINAL BLENDED FORECAST FOR AUGUST ====\")\n",
    "print(f\"Expected number of deals: {blended_deals:.1f}\")\n",
    "print(f\"Expected volume: £{blended_volume:,.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "34bd3e19-ad18-4f3a-bc4b-abef3b1ad97a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==== FINAL BLENDED FORECAST FOR AUGUST (70% Pipeline, 30% Time Series) ====\n",
      "Expected number of deals: 151.1\n",
      "Expected volume: £137,863,811.47\n"
     ]
    }
   ],
   "source": [
    "# Inputs from forecast\n",
    "pipeline_expected_volume = 153_109_866.28\n",
    "pipeline_expected_deals = 187.3\n",
    "\n",
    "ts_expected_volume = 102_289_683.58\n",
    "ts_expected_deals = 66.7\n",
    "\n",
    "# Weighted blending\n",
    "blended_volume = (0.7 * pipeline_expected_volume) + (0.3 * ts_expected_volume)\n",
    "blended_deals = (0.7 * pipeline_expected_deals) + (0.3 * ts_expected_deals)\n",
    "\n",
    "# Display \n",
    "print(\"\\n==== FINAL BLENDED FORECAST FOR AUGUST (70% Pipeline, 30% Time Series) ====\")\n",
    "print(f\"Expected number of deals: {blended_deals:.1f}\")\n",
    "print(f\"Expected volume: £{blended_volume:,.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "d65e0525-f56b-4219-bf31-9d15869e9705",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== SARIMAX Forecast for August 2025 ===\n",
      "Expected volume: £198,846,755.07\n",
      "Expected number of deals: 89.4\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from statsmodels.tsa.statespace.sarimax import SARIMAX\n",
    "\n",
    "# Inputting time series data\n",
    "volume_data = {\n",
    "    '2025-03-01': 331_572_700,\n",
    "    '2025-04-01': 166_550_300,\n",
    "    '2025-05-01': 43_981_340,\n",
    "    '2025-06-01': 140_656_500,\n",
    "    '2025-07-01': 154_000_000  # Updated July\n",
    "}\n",
    "\n",
    "deal_data = {\n",
    "    '2025-03-01': 315,\n",
    "    '2025-04-01': 131,\n",
    "    '2025-05-01': 147,\n",
    "    '2025-06-01': 140,\n",
    "    '2025-07-01': 134\n",
    "}\n",
    "\n",
    "# Creating time series objects\n",
    "volume_series = pd.Series(volume_data)\n",
    "volume_series.index = pd.to_datetime(volume_series.index)\n",
    "volume_series.index.freq = 'MS'\n",
    "\n",
    "deal_series = pd.Series(deal_data)\n",
    "deal_series.index = pd.to_datetime(deal_series.index)\n",
    "deal_series.index.freq = 'MS'\n",
    "\n",
    "# Fitting SARIMAX model\n",
    "volume_model = SARIMAX(volume_series, order=(1, 1, 0), trend='t')\n",
    "deal_model = SARIMAX(deal_series, order=(1, 1, 0), trend='t')\n",
    "\n",
    "volume_fit = volume_model.fit(disp=False)\n",
    "deal_fit = deal_model.fit(disp=False)\n",
    "\n",
    "# Forecast August 2025\n",
    "volume_forecast = volume_fit.forecast(1).iloc[0]\n",
    "deal_forecast = deal_fit.forecast(1).iloc[0]\n",
    "\n",
    "print(\"=== SARIMAX Forecast for August 2025 ===\")\n",
    "print(f\"Expected volume: £{volume_forecast:,.2f}\")\n",
    "print(f\"Expected number of deals: {deal_forecast:.1f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "e2afd447-bbe7-41f6-b73b-d939ce497e06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==== FINAL BLENDED FORECAST FOR AUGUST SARIMAX model (70% Pipeline, 30% Time Series) ====\n",
      "Expected number of deals: 157.9\n",
      "Expected volume: £166,830,932.92\n"
     ]
    }
   ],
   "source": [
    "# Inputs from forecast\n",
    "pipeline_expected_volume = 153_109_866.28\n",
    "pipeline_expected_deals = 187.3\n",
    "\n",
    "ts_expected_volume = 198_846_755.07\n",
    "ts_expected_deals = 89.4\n",
    "\n",
    "# Weighted blending\n",
    "blended_volume = (0.7 * pipeline_expected_volume) + (0.3 * ts_expected_volume)\n",
    "blended_deals = (0.7 * pipeline_expected_deals) + (0.3 * ts_expected_deals)\n",
    "\n",
    "# Display \n",
    "print(\"\\n==== FINAL BLENDED FORECAST FOR AUGUST SARIMAX model (70% Pipeline, 30% Time Series) ====\")\n",
    "print(f\"Expected number of deals: {blended_deals:.1f}\")\n",
    "print(f\"Expected volume: £{blended_volume:,.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "dd5a9407-a401-4c18-a9d6-43d65d17a087",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==== FINAL BLENDED FORECAST FOR AUGUST SARIMAX ====\n",
      "Expected number of deals: 138.4\n",
      "Expected volume: £175,978,310.68\n"
     ]
    }
   ],
   "source": [
    "# Inputs from pipeline forecast\n",
    "pipeline_expected_volume = 153_109_866.28\n",
    "pipeline_expected_deals = 187.3\n",
    "\n",
    "# Inputs from time series forecast\n",
    "ts_expected_volume = 198_846_755.07\n",
    "ts_expected_deals = 89.4\n",
    "\n",
    "# Simple average (50/50 weighting)\n",
    "blended_volume = (pipeline_expected_volume + ts_expected_volume) / 2\n",
    "blended_deals = (pipeline_expected_deals + ts_expected_deals) / 2\n",
    "\n",
    "# Output the blended forecast\n",
    "print(\"\\n==== FINAL BLENDED FORECAST FOR AUGUST SARIMAX ====\")\n",
    "print(f\"Expected number of deals: {blended_deals:.1f}\")\n",
    "print(f\"Expected volume: £{blended_volume:,.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdc1fa57-47fb-4a83-a2d9-668b465f9be2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
